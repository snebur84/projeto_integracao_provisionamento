---
# Bootstrap TF backend (S3 + DynamoDB) if missing, then run terraform
# and deploy the application via SSM.
# Changes requested:
# - Use a simple, valid default bucket name (provisionbucket-<env>)
# - Always pass aws-session-token in Configure AWS credentials
on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Deployment environment (e.g. prod)"
        required: true
        default: "prod"

name: Bootstrap + Terraform deploy

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      TFSTATE_BUCKET: ${{ secrets.TFSTATE_BUCKET || '' }}
      TFSTATE_LOCK_TABLE: ${{ secrets.TFSTATE_LOCK_TABLE || '' }}
      ENVIRONMENT: ${{ github.event.inputs.environment }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.12

      - name: Smoke check tools
        run: |
          aws --version
          terraform version

      - name: Bootstrap backend if missing
        id: bootstrap
        working-directory: infra/terraform
        run: |
          set -euo pipefail

          REGION="${AWS_REGION:-us-east-1}"
          ENV="${ENVIRONMENT:-prod}"

          # Decide bucket name. Use provided secret if present,
          # otherwise use a simple preset name per environment.
          if [ -n "${TFSTATE_BUCKET}" ]; then
            BUCKET="${TFSTATE_BUCKET}"
            echo "Using TFSTATE_BUCKET from secret: ${BUCKET}"
          else
            BUCKET="provisionbucket-${ENV}"
            echo "No TFSTATE_BUCKET secret; using default: ${BUCKET}"
          fi

          if [ -n "${TFSTATE_LOCK_TABLE}" ]; then
            TABLE="${TFSTATE_LOCK_TABLE}"
          else
            TABLE="${BUCKET}-locks"
          fi

          echo "bucket=${BUCKET}" >> "$GITHUB_OUTPUT"
          echo "dynamodb_table=${TABLE}" >> "$GITHUB_OUTPUT"
          echo "region=${REGION}" >> "$GITHUB_OUTPUT"

          # Create bucket if missing
          if aws s3api head-bucket --bucket "${BUCKET}" 2>/dev/null; then
            echo "Bucket ${BUCKET} exists or accessible"
          else
            echo "Creating bucket ${BUCKET} in ${REGION}..."
            if [ "${REGION}" = "us-east-1" ]; then
              aws s3api create-bucket --bucket "${BUCKET}"
            else
              aws s3api create-bucket \
                --bucket "${BUCKET}" \
                --create-bucket-configuration \
                LocationConstraint="${REGION}"
            fi

            aws s3api put-bucket-versioning \
              --bucket "${BUCKET}" \
              --versioning-configuration Status=Enabled

            printf '%s\n' '{' \
              '  "Rules": [' \
              '    {' \
              '      "ApplyServerSideEncryptionByDefault": {' \
              '        "SSEAlgorithm": "AES256"' \
              '      }' \
              '    }' \
              '  ]' \
              '}' > enc.json

            aws s3api put-bucket-encryption \
              --bucket "${BUCKET}" \
              --server-side-encryption-configuration file://enc.json

            echo "Created bucket ${BUCKET}"
          fi

          # Create DynamoDB table for locking if missing
          if aws dynamodb describe-table \
            --table-name "${TABLE}" --region "${REGION}" \
            >/dev/null 2>&1; then
            echo "DynamoDB table ${TABLE} exists"
          else
            echo "Creating DynamoDB table ${TABLE}..."
            aws dynamodb create-table \
              --table-name "${TABLE}" \
              --attribute-definitions \
              AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region "${REGION}"
            aws dynamodb wait table-exists \
              --table-name "${TABLE}" --region "${REGION}"
            echo "Created table ${TABLE}"
          fi

          # Write backend.hcl
          printf 'bucket = "%s"\n' "${BUCKET}" > backend.hcl
          printf 'key    = "%s/terraform.tfstate"\n' "${ENV}" >> backend.hcl
          printf 'region = "%s"\n' "${REGION}" >> backend.hcl
          printf 'dynamodb_table = "%s"\n' "${TABLE}" >> backend.hcl
          printf 'encrypt = true\n' >> backend.hcl

          terraform init -input=false \
            -backend-config=backend.hcl -reconfigure

      - name: Terraform validate & plan
        working-directory: infra/terraform
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          set -euo pipefail
          terraform validate
          terraform plan -out=tfplan -input=false

      - name: Terraform apply
        working-directory: infra/terraform
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          set -euo pipefail
          terraform apply -input=false -auto-approve tfplan

      - name: Upload provision script (guarded)
        working-directory: infra/terraform
        run: |
          set -euo pipefail
          if [ ! -f tfplan ]; then
            echo "tfplan not present; skipping upload"
            exit 0
          fi
          STAGING_BUCKET="${{ steps.bootstrap.outputs.bucket }}"
          aws s3 cp scripts/provision_ubuntu_ec2.sh \
            "s3://${STAGING_BUCKET}/provision_ubuntu_ec2.sh" \
            --acl private

      - name: Deploy via SSM (guarded)
        working-directory: infra/terraform
        run: |
          set -euo pipefail
          STAGING_BUCKET="${{ steps.bootstrap.outputs.bucket }}"
          INSTANCE_ID=$(terraform output -raw instance_id 2>/dev/null || true)
          if [ -z "${INSTANCE_ID}" ]; then
            echo "No instance id found; skipping SSM deploy"
            exit 0
          fi

          CMD1="aws s3 cp s3://${STAGING_BUCKET}/provision_ubuntu_ec2.sh"
          CMD2="/tmp/provision_ubuntu_ec2.sh && chmod +x"
          CMD3="/tmp/provision_ubuntu_ec2.sh && /bin/bash"
          CMD="${CMD1} ${CMD2} ${CMD3}"
          CMD_JSON=$(printf '["%s"]' "$CMD")

          aws ssm send-command \
            --instance-ids "${INSTANCE_ID}" \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy via SSM" \
            --parameters commands="$CMD_JSON" \
            --timeout-seconds 900 \
            --query "Command.CommandId" --output text

      - name: Print backend info
        run: |
          echo "bucket=${{ steps.bootstrap.outputs.bucket }}"
          echo "dynamodb_table=${{ steps.bootstrap.outputs.dynamodb_table }}"
          echo "region=${{ steps.bootstrap.outputs.region }}"
